General:
  use_residual: False
  use_layer_norm: False
  use_activation: False
  loader_workers: 2
  eval_every: 5
  wd: 0.0
  self_loop_weight: 0.0
  num_samples: 32000
  lr: 0.001
  dropout_final: .0
  dropout_hidden: .0
  max_epochs: 100
  batchNorm_final: True
  batchNorm_hidden: True
  mlp_activation_hidden: relu
  mlp_activation_final: relu
  test_batch_size: 1024
  val_batch_size: 1024
  accum_grad: 1
  repeat: 1
  batch_size: 1
  learnable_embedding: True
  optim_type: Adam
Task_specific:
  SW:
    Ring:
      batch_size: 1024
      dim: 64
      lr_factor: .7
      num_samples: 6000
      max_epochs: 150
      train_fraction: 5000
      mlp_layers: 3
      mlp_activation_hidden: leaky
      mlp_activation_final: leaky
    CliqueRing:
      batch_size: 1024
      dim: 64
      lr_factor: .7
      num_samples: 6000
      train_fraction: 5000
      mlp_layers: 3
      mlp_activation_hidden: leaky
      mlp_activation_final: leaky
    CrossRing:
      batch_size: 1024
      dim: 64
      lr_factor: .7
      num_samples: 6000
      train_fraction: 5000
      mlp_layers: 3
      mlp_activation_hidden: leaky
      mlp_activation_final: leaky
    Tree:
      train_fraction: 0.8
      batch_size: 1024
      lr_factor: .7
      self_loop_weight: 0.0
      accum_grad: 1
      mlp_layers: 0
      max_epochs: 1000
      dim: 64
      mlp_activation_hidden: relu
      mlp_activation_final: relu
      lr: 0.001
      use_residual: True
      use_layer_norm: False
    Cora:
      # Done.
      dim: 128
      lr_factor: .5
      mlp_layers: 0
      wd: 0.00001
      dropout_final: .1
      dropout_hidden: .1
      lr: 0.001 
      max_epochs: 80
      self_loop_weight: 0.1
      optim_type: AdamW
      use_residual: True
      use_layer_norm: True
      eval_every: 5
    Actor:
      # Done.
      batch_size: 1
      dim: 128
      lr_factor: .7
      mlp_layers: 3
      wd: 0.00001
      dropout_final: .1
      dropout_hidden: .1
      lr: 0.005
      max_epochs: 50
      self_loop_weight: 0.1
      optim_type: AdamW
      use_residual: True
      use_layer_norm: True
    Squi:
      batch_size: 1
      dim: 128
      lr_factor: .7
      mlp_layers: 0
      use_residual: True
      use_layer_norm: True
      wd: 0.00001
      lr: 0.001
      max_epochs: 80
      dropout_final: 0.1
      dropout_hidden: 0.1
      self_loop_weight: 0.2
      optim_type: AdamW
    Texas:
      batch_size: 1
      dim: 128
      lr_factor: .7
      mlp_layers: 0
      use_residual: True
      use_layer_norm: True
      wd: 0.00001
      dropout_final: .1
      dropout_hidden: .1
      lr: 0.001
      max_epochs: 80
      self_loop_weight: 0.1
      optim_type: AdamW
    Corn:
      batch_size: 1
      dim: 128
      lr_factor: .7
      mlp_layers: 0
      wd: 0.0000
      dropout_final: .1
      dropout_hidden: .1
      lr: 0.001
      max_epochs: 80
      eval_every: 5
      self_loop_weight: 0.1
      optim_type: Adam
      use_residual: True
      use_layer_norm: True
    Wisc:
      batch_size: 1
      dim: 128
      lr_factor: .7
      mlp_layers: 0
      wd: 0.00001
      dropout_final: .1
      dropout_hidden: .1
      lr: 0.001
      max_epochs: 70
      self_loop_weight: 0.1
      optim_type: Adam
      eval_every: 5
      use_residual: True
      use_layer_norm: True
    Cham:
      batch_size: 1
      dim: 128
      lr_factor: .7
      mlp_layers: 0
      residual: True
      layer_norm: True
      wd: 0.00001
      dropout_final: .1
      dropout_hidden: .1
      lr: 0.001
      max_epochs: 80
      self_loop_weight: 0.1
      optim_type: AdamW
    Cite:
      batch_size: 1
      dim: 128
      lr_factor: .5
      mlp_layers: 0
      use_residual: True
      use_layer_norm: False
      wd: 0.00001
      dropout_final: .1
      dropout_hidden: .1
      lr: 0.001
      max_epochs: 50
      self_loop_weight: 0.1
      optim_type: Adam
      learnable_embedding: True
    Pubm:
      batch_size: 1
      dim: 128
      lr_factor: .7
      mlp_layers: 0
      residual: True
      layer_norm: True
      wd: 0.00001
      dropout_final: .1
      dropout_hidden: .1
      lr: 0.005
      max_epochs: 80
      self_loop_weight: 0.1
      optim_type: Adam
  GAT:
    Tree:
      num_samples: 32000
      train_fraction: 0.8
      batch_size: 1024
      lr_factor: .5
      max_epochs: 100
      dim: 64
      lr: 0.001
      repeat: 100
      eval_every: 1
      residual: True
      layer_norm: True
    Bridge:
      lr: 0.005
      batch_size: 256
      dim: 64
      lr_factor: .5
      num_samples: 6000
      train_fraction: 5000
      max_epochs: 100
      loop_weight: 0.0
    Ring:
      batch_size: 256
      dim: 64
      lr_factor: .5
      num_samples: 6000
      train_fraction: 5000
      max_epochs: 100
      optim_type: Adam
  GIN:
    Tree:
      num_samples: 32000
      train_fraction: 0.8
      batch_size: 1024
      lr_factor: .5
      max_epochs: 100
      dim: 32
      lr: 0.001
      residual: False
      layer_norm: False
      repeat: 100
      eval_every: 1
    Cora:
      batch_size: 1
      dim: 128
      lr_factor: .85
      residual: True
      layer_norm: True
      wd: 0.0001
      dropout_final: .1
      dropout_hidden: .1
      lr: 0.001 # 0.01
    Ring:
      batch_size: 256
      dim: 64
      lr_factor: .5
      num_samples: 6000
      train_fraction: 5000
      max_epochs: 100
      optim_type: Adam
  GCN:
    Tree:
      num_samples: 32000
      train_fraction: 0.8
      batch_size: 1024
      lr_factor: .5
      max_epochs: 100
      dim: 32
      lr: 0.001
      residual: True
      layer_norm: True
      repeat: 100
      eval_every: 1
    Ring:
      batch_size: 256
      dim: 64
      lr_factor: .5
      num_samples: 6000
      train_fraction: 5000
      max_epochs: 100
      optim_type: Adam

    Bridge:
      lr: 0.005
      batch_size: 256
      dim: 64
      lr_factor: .5
      num_samples: 6000
      train_fraction: 5000
      max_epochs: 100
      loop_weight: 0.0
  GGNN:
    Tree:
      num_samples: 32000
      train_fraction: 0.8
      batch_size: 1024
      lr_factor: .5
      max_epochs: 100
      dim: 64
      reduce_every: 1
      lr: 0.001
      residual: False
      layer_norm: False
      repeat: 100
      eval_every: 1
    Cora:
      batch_size: 1
      dim: 128
      lr_factor: .85
      num_heads: 3
      residual: True
      layer_norm: True
      wd: 0.0001
      dropout_final: .1
      dropout_hidden: .1
      lr: 0.001
    Ring:
      batch_size: 256
      dim: 64
      lr_factor: .5
      num_samples: 6000
      train_fraction: 5000
      max_epochs: 100
      optim_type: Adam
  SAGE:
      Ring:
        batch_size: 256
        dim: 64
        lr_factor: .5
        num_samples: 6000
        train_fraction: 5000
        max_epochs: 100
        optim_type: Adam
